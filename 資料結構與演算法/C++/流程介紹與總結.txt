第一章-簡介
    老師GitHub: https://github.com/liuyubobobo/Play-with-Algorithms
第二章-排序基礎
    1.Selection Sort
    2.泛型Selection Sort
    3.隨機生成測資
    4.測試算法性能
    5.Insertion Sort
    6.改進Insertion Sort
    7.關於O(n^2)的算法思考
[總結]
    SelectionSort 與 InsertionSort 都是O(n^2)的時間複雜度
    但是InsertionSort經過改進之後，效能會比SelectionSort好很多
    因為可以跳過很多不必要的循環，而且InsertionSort在處理 近乎有序的資料時，
    有些時候，速度可以逼近或超越O(logn)算法的效能，可以接近O(n)。

    InsertionSort算法的延伸就是Shell Sort(希爾)算法
[延伸]
    Bubble Sort 實作與改進
    Shell Sort 實作與改進
第三章-高級排序算法
    1.MergeSort
    2.MergeSort優化
    3.由下往上的MergeSort
    4.QuickSort
    5.QuickSort改進
    6.雙路QuickSort
    7.三路QuickSort
[總結]
    MergeSort的時間複雜度是nlog(n)
    QuickSort也是nLog(n)
    
    QuickSort是由前往後掃描 並陣列分成小於與大於等於的左右兩側陣列--->左右半部不平衡
    DoubleQuickSort透過 由前往後 與 由後往前 掃描，將陣列分成小於等於與大於等於的陣列--->左右半部較平衡
    DoubleQuickSort能夠將相等的元素平均的分布到左右陣列中 避免QuickSort中的每次partition左右陣列不平衡問題
    QuickSortThreeWay是基於DoubleQuickSort改良的，是將陣列分成 小於、等於、大於 三個區塊
    這樣做，對於重複且相等的資料，能有更高的效能--->因為等於的部分不用處理 只需要處理 小於、等於的兩個部分

    全部隨機元素:DoubleQuickSort>QuickSort>QuickSortThreeWay
    近乎有序元素:DoubleQuickSort>QuickSort>QuickSortThreeWay
    大量相等元素:QuickSortThreeWay>DoubleQuickSort>QuickSort

    再大多數情況下(全部隨機、近乎有序)
    DoubleQuickSort的表現都比QuickSort與QuickSortThreeWay好
    但是在大量相同元素下
    QuickSortThreeWay的優勢發會出來，效能比DoubleQuickSort和QuickSort好很多
[延伸用途-分治算法的延伸]
1.MergeSort的merge方法找 順/逆序對--->時間複雜度O(nlogn)
    順序對: 2 3 (2<3)
    逆序對: 2 1 (2<1)
    ---詳情:看Imooc的影片---
2.QuickSort的partition找topK(一組資料中 第k個大/小的元素)--->時間複雜度O(n)
    依照partition的標定點來判斷當前標定點是整個數列的第幾大元素
    依照要找的需求 往前或往後partition再看標定點來找第k大/小的元素
    ---詳情:看Imooc的影片---

第四章-堆與堆排序
    1.使用堆--->方便維護動態型的資料
    2.最大堆(MaxHeap)
    3.Shift Up (將新加入的元素放到適合的位置)--->由下往上找
    4.Shift Down (將更動後的堆重新整理)--->由上往下找
    5.基礎堆排序HeapSort vs Heapify原理排序
        基礎堆排序:將每個元素逐一放到堆中並Shift Up --->時間複雜度O(nlogn)
        Heapify原理排序:一次性將陣列存入堆中並將非葉節點逐一Shift Down--->時間複雜度O(nlogn)
    6.原地HeapSort
        運用HeapSort的原理，直接對資料做Heapify並排序(也就是將資料直接看作MaxHeap)
    [小總結]
        1.基礎的HeapSort因為要將資料額外拿出來，逐個insert並shiftUp
          再逐個依次放進要排序的陣列中，因此速度最慢
        2.Heapify是直接將陣列全部放進MaxHeap中，再做shiftDown
          是從第一個非葉節點(也就是有子節點的父節點)開始排序
          然後個依次放進要排序的陣列中
          因為省略掉葉節點，排序速度會相對比基礎HeapSort好一些
        3.原地HeapSort就是結合以上兩點，直接將陣列看作HeapSort
          從非葉節點開始創造MaxHeap
          並把每次的最大值放到陣列後面，完成排序
          因為省略掉複製資料到另一個資料結構中，速度是相對快的
        4.排序速度:原地HeapSort>使用Heapify整理的MaxHeap>基礎HeapSort
    7.索引堆(Index Heap):用來避免交換複雜資料所產生的Overhead--->使用一個indexes陣列來表示每個元素在data陣列中的索引值，只交換index不交換實際的元素
        [假設]要查找data[x]
        為了要查找x，必須去遍歷indexes陣列
        使得indexes[y]=x

        此時data[indexes[y]]才是我們要找的資料

        此過程的時間複雜度是O(n)
        而連續查找則會花費n個 時間單位
    8.優化索引堆的查詢問題
        因為IndexHeap無法直接查找到資料(即data[?])
        必須透過indexes陣列，而每次要查找特定的資料，就要遍歷整個indexes陣列
        會使堆排序的時間複雜度從O(nlogn)退化成O(n^2)
        因此我們多使用一個陣列叫做reverse陣列，
        用來查找data[x]在indexes[y]的位置
        此時rev的rev[x]的值會是y，即rev[x]=y
        
        [假設]更新了data[4]
        為了要重新維護indexes陣列，使其滿足IndexMaxHeap，
        必須先找到4這個索引值 是存放在indexes陣列中的哪個元素呢(即indexes[?]=4)
        透過reverse陣列查找

        查找rev[4]--->rev[4]的值會是9(即rev[4]=9)
        代表data[4]這個資料的索引值是存放在indexes[9]的位置(即indexes[9]=4)

        data陣列、revese陣列、indexes陣列
        關係是
        data[x]=資料
        indexes[y]=x
        rev[x]=y
        有此可推倒
        indexes[rev[x]]=x--->因為將rev[x]替換成y--->則變成indexes[y]=x
        rev[indexes[y]]=y--->因為將indexes[y]替換成x--->則會變成rev[x]=y
[實際用途]
    1.電腦遊戲中的角色AI判斷邏輯
        將敵人當作物件放入角色的AI判斷邏輯，使用堆的結構
        透過特定的邏輯 來決定要攻擊的人  例如依照:優先度最高(舉例:最大堆中優先度就是:數值最大的元素)的敵人最先攻擊
        新的敵人--->Insert到堆中
        敵人死亡--->Extract出堆
    2.多個數值排序
        假設要從小到大排序出4個整數的大小
        可以實作出最小堆，然後將4個元素都丟進去(一次一個insert或全部丟進去heapify)
        然後每次extract出來的值就是4個當中最小的
        經過4次的extract則會輸出第1小、第2小...第4小的整數
    3.多路合併問題(MergeSort的分割後合併問題)
        經典的MergeSort是分割成2個部分(左右陣列)
        而我們可以分割成n個部分，每個部份是1個元素
        此時，要將這n個部分比大小排序(創建最小/最大堆--->然後一直extract就好了)
        多路的MergeSort就演變成了一個heapSort的問題
    4.用來查找N個元素中前M個大的元素
        假設要在10000個元素中找到前100大的元素
        則我們可以實作一個容量為100的最小堆
        然後開始將這10000個元素一個個放入最小堆
        當最小堆的元素個數>100時，就extract出最小的元素
        當所有元素都放入最小堆後，這個最小堆中的元素就是前100大的元素了
[堆的擴展與延伸]
    1.二項堆
    2.Fibonacci Heap
    [思考]最小堆vsQuickSort的Partition
    QuickSort的partition找topK 可以找到『第』k個元素(第k個元素)---->時間複雜度O(n)
    最小堆找topK 可以找到『前』k個元素(第1...第k個元素)--->時間複雜度--->O(nlogn)
[排序算法總結]有關 時間複雜度 額外空間 是否穩定(Stable)
---請看『所有排序算法總結』---

第五章-二分搜索樹
    1.二叉查找法Binary Search 
        用來解決 查找問題Searching Problem
        時間複雜度:O(logn)
        [問題]在求中間值時:(l+r)/2=mid--->可能會Overflow
              改用l+(r-l)/2=mid的運算則不會Overflow
              [證明](l+r)/2=mid 等於 l+(r-l)/2=mid 相等
              l+(r-l)/2=mid--->l+((2*mid-l)-l)/2=mid--->l+(2*mid-2*l)/2=mid
              l+(mid-l)=mid--->mid=mid--->兩者相等
        [補充]上下界問題:floor and ceil 或者稱 lowerBound and UpperBound
            當一份資料中擁有相同元素時，查找此元素時
            floor(lowerBound)會標記出此元素第一次出現的位置
            ceil(UpperBound)會標記出此元素最後一次出現的位置
            值得思考的是，如果要查找的元素不存在
            則floor會標記出最靠近此元素的左側元素最後一個人(最接近此元素第一次出現的位置)
            而ceil會標記出最靠近此元素的右側元素第一個人(最接近此元素最後出現的位置)
            [舉例]
            編號:  1 2 3 4 5 6
            數值:  7 7 7 9 9 9
            查找數值8--->找不到
            floor:編號3
            ceil:編號4
    2.二分搜索樹Binary Search Tree (BST)
        查找表的實現-字典數據結構
        也就是Key-Value Pair(鍵值對)
        最典型的應用:字典(單詞-詞意)
    [優點]高效的增刪改查 動態維護資料--->都是逼近O(logn)
    [結構]是棵二叉樹，每個節點的鍵值都大於以左節點為根節點的BST，且都小於以右節點為根節點的BST，但不一定是一棵完全二叉樹
    3.深度優先遍歷DFS
        前序遍歷:先訪問當前節點 再依次遞迴左子樹 最後是右子樹
        中序遍歷:先遞迴左子樹 接著在訪問當前節點 最後才是右子樹
        後續遍歷:先遞迴左右子樹再遞迴自己

        使用中序遍歷二分搜索樹時，剛好就是從小到大的排序結果
        使用後序遍歷來釋放二分搜索樹
    4.廣度優先遍歷BFS
        使用一個輔助資料結構Queue(先進先出)
        將根節點推入Queue 然後開始拿出元素做處理
        每拿出一個元素 就把此元素的左右節點推入Queue
        直到沒有元素存在 在Queue中
    5.刪除最大或最小值
        刪除最小值:先遞迴到整顆BST的最左下節點，刪除此節點，並以此節點的右節點當作新的節點回傳
        刪除最大值:先遞迴到整顆BST的最又下節點，刪除此節點，並以此節點的左節點當作新的節點回傳
    6.刪除任意元素(Hibbard Deletion)--->時間複雜度O(logn)
        假設一個節點d要被刪除
        先找到節點d右子樹的最小節點s
        刪除s節點，
        將節點s的右邊節點指向d的右節點
        將節點s的左邊節點指向d的左節點
        並回傳s節點
        這樣一來，就完成 將d刪除並使用s取代
    7.二分搜索樹的順序性
        1.回答最小最大值(Minimum/Maximum)是誰
        2.找到前驅後繼(Predecessor/Successor)是誰
        3.找到元素的Floor與Ceil
            Predecessor 小於自己的第個節點
            Successor 大於自己的第個節點
            若節點不存在
            則 沒有Predecessor與Successor
            但 有Floor與Ceil
            Floor 小於自己的第一個節點
            Floor 大於自己的第一個節點
        4.回答Rank問題
            某個節點再整顆BST中排名第幾
        5.回答Select問題
            排名第幾的節點是誰
        
            Rank與Select是相反的問題
            假設一節點K
            Rank:請問K是BST中的第r名?
            Select:請問第r名的節點是誰?
    8.二分搜尋樹的效能侷限性--->當元素有序時--->效能退化問題
        當資料呈現排序完成的狀態 則二分搜索樹的深度就會非常深
        此時二分搜尋數會變成 鏈表的狀態 此時性能會退化成 O(n) 級別

        可以透過更改二分搜尋樹實現(結構) 使得二叉樹無法退化成鏈表 保證了效能
        也就是 平衡二叉樹:紅黑樹

        [紅黑樹] 有兩棵子樹，且左右兩棵子樹的高度差不會超過1--->保證了整個二叉樹的高度是O(logn)級別的

        其他的平衡二叉樹
        2-3 tree
        AVL tree
        Splay tree (伸展樹)

        [平衡二叉樹與堆的結合:Treap]

        [trie結構]一種數據結構，使得查找時間(時間複雜度)與查找的資料長度相關的
    9.樹形問題
        參考影片-[樹形問題與搜索問題]

第六章-併查集(Union Find)
    1.介紹與基礎-功能
        1.一種高效的輔助資料結構，用來輔助『圖論演算法』，來高效實現 圖的算法
        2.一種很不一樣的 樹形結構
        3.可以非常高效地解決 『Connectivity Problem 連結問題』的問題
            [實際應用]
            1.一個網路中 節點之間的連接狀態
                網路:可以指 用戶與用戶間的關係 等等 組成的一個網路
                    例如:
                        1.兩個人AB， 是否能透過A的FB直接認識B呢?
                        2.兩台數據機 是否能夠直接訪問彼此呢?
            2.數學中『集合』的實現
        4.不能解決 路徑問題
        
        [思考連接問題vs路徑問題]
        連接問題:是否相連?但不涉及 如何連接 路徑為何?
        路徑問題:如何連接、連接路徑?
    2.Union Find 分別就是兩個動作
        union(p,q):將p和q合併起來
        find(p):查找p再哪個組
        [可以解決問題]isConnected問題
    4.Quick Find 的方法來 實現 併查集
        優點: 查詢是否相連效能好O(1)--->操作n次--->O(1)
        缺點: 合併效能差O(n)--->操作n次--->O(n^2)
    5.Quick Union 的方法來 實現 併查集
        優點:合併效能提升--->時間複雜度與 樹高 成正比
        缺點:因為合併操作(沒有檢查 而是直接將前者與後者合併) 最後產生的樹可能高度無法確定--->需要優化
    6.基於Size優化Quick Union的Union操作 
        透過比較兩群所擁有的元素個數，再決定 兩者 誰要合併誰 
        元素少的根節點往元素多的根節點合併
        優點:比不檢查的合併 更能夠避免樹高的高的狀況
        缺點:有些狀況下 元素少往元素多合併 未必是最佳解--->可以再優化
    7.基於Rank優化Quick Union的Union操作 
        透過比較兩群產生出來的樹高 再決定 兩者 誰要合併誰
        優點:最大化的 降低樹的高度
    [比較]Size的優化 與Rank的優化
    不管事基於Size或是基於Rank優化QuickUnion實作的QuickFind
    理論上來說基於Rank的優化>=Size的優化
    但其實在實際運行上 沒有太大的差別 因為Rank的優化會比Size優化判斷更多東西
    [建議]採用Rank優化QuickUnion會比較好一些些
    8.路徑壓縮(Path Compression)優化
        --參考 路徑壓縮優化 影片--
[總結]
    若要實現一個併查集QuickFind時
    比較經典的方式是使用QuickUnion的方式實作
    可配合Rank(樹高紀錄)與Path Compression(路徑壓縮)來做優化
    此時
        1.在Find操作時 是Path Compression 在整理樹高 (調整元素的指向)
        2.在Union操錯時 是通過判斷Rank值 在整理樹高 (合併樹與樹)
    使得此併查集 在 查 與 併 的動作 時間複雜度都是近乎O(1)--->實際上並非O(1)只是接近

    Size與Rank優化 都是在 Union(合併) 操作時 
    透過判斷群集中的數量或群集的樹高 來決定誰與誰合併
    (小的群集往大的群集合併、矮的樹向高的樹和併)
    以此降低樹的高度 達到提升效能的效果

    Path Compression 是在 Find(查詢) 操作時 
    一邊跳躍式向根節點查詢 一邊做 樹的整理 嘗試降低樹的高度 達到提升效能的效果
    (將每層元素重新指向上n層的元素，直到指向根節點)
[建議]
    若要實現一個併查集QuickFind時
    比較經典的方式是使用QuickUnion的方式實作
    並Path Compression(路徑壓縮)來做優化
    就已經足夠應付大多數的場景
[比較]實際運行速度
QuickUnion+Path Compression >= QuickUnion+Rank+Path Compression >= QuickUnion+Rank 

第七章-圖論Graph Theory
    1.圖論基礎構造
        1.節點(Vertex)
        2.邊(Edge)
        能表示很多事情
        ex: 交通運輸 節點是城市 邊是道路
            社交關係 節點是人 邊是 人與人的關係
            網路關係 節點是路由器 邊是連接線路  
            工作安排 節點是工作內容 邊是 關聯或先後順序
    2.圖的分類
        1.方向性質
            1.無向圖(Undirected Graph)
                ex:人際關係 節點是人 邊是人與人的關係 這種圖 沒有方向的意義
            無向圖其實可以看做是 一種『特殊的』有向圖
            可以想像是兩個有方向的邊(一個邊A指向B，另一個邊B指向A)
            2.有向圖(Directed Graph)
                ex:有限自動機 節點是事件 邊是事件與事件在轉移的過程 此時 方向是有意義的
            有向圖 是有『不對稱性』的概念
        2.權重性質--->權 就是一個 數值 --->連接節點之間的邊 是否有 數值
            1.無權圖(Unweighted Graph)
                ex:人際關係 節點是人 邊是代表人與人之間是否有關係 此時 邊 是沒有數值概念的
            2.有權圖(Weight Graph)
                ex:交通運輸 節點是城市 邊是道路 邊上可能代表 節點之間的距離 此時 邊 是有數值概念的
        3.圖的連通性質
            1.不連通
            2.連通
        4.圖的簡單圖概念(Simple Graph)
            1.自環邊(Self-Loop):邊是連接自己的節點(自己節點出發連接到自己的節點)
            2.平行邊(Parallel-edges):兩個節點之間 存在多個邊(節點到節點 有多條邊可以走)
    2.圖的表示法
        1.鄰接矩陣(Adjacency Matrix):使用二維陣列表示 有向圖和無向圖
            Row表示 每個節點
            Col表示 當前Row的節點與其他所有節點是否相連
        2.鄰接表(Adjacency List):使用list來表示 有向圖和無向圖
            Row表示 每個節點
            Col表示 當前Row的節點與哪些節點相連
        鄰接表 適合表示 稀疏圖(Sparse Graph):也就是 邊數比較少的圖
        鄰接矩陣 適合表示 稠密圖(Dense Graph):也就是 邊數比較多的圖

        何謂稀疏與稠密呢?
        其實就是 節點總數 與 節點之間最多邊的差異
        ex:60個節點 節點之間最多6條邊 ---> 60遠大於6 --->稀疏圖
        
        [完全圖]:每個節點都與別的節點有邊--->經典的稠密圖
        
        [比較]Adjacency Matrix 與 Adjacency List 的查找邊(hasEdge)效能
            Adjacency Matrix 可以透過索引值直接知道 是否相連--->時間複雜度O(1)
            Adjacency List 必需遍歷一次才能確認是否相連--->時間複雜度O(n)
    3.相鄰節點的遍歷
        從一個節點透過所有的邊遍歷相鄰的節點
        Adjacency Matrix 要遍歷所有節點才能知道跟那些節點相鄰--->時間複雜度O(v)--->v是vertex節點數量的意思
        Adjacency List 則是直接紀錄了跟哪些人相鄰
        
        使用iterator的概念 來走訪 每個節點 和 與之相連的節點
        可以避免 資料曝露 也可避免資料複製的overhead
        詳情請看 實作的程式碼
    4.圖的遍歷
        深度優先遍歷DFS
            從一個點 一直往下走訪 直到無法再走訪(與樹很像)
            但需要考慮環的問題--->需要紀錄哪些人被遍歷
            [功能]能夠求 連通分量(Graph Component)--->一個圖 有幾塊 互不相連的子圖
            [延伸功能]為每個節點都標上群組的id 可以透過id來分辨 哪些節點是同一個子圖
        廣度優先遍歷BFS
    5.使用深度優先遍歷 獲得兩個節點之間的路徑(不一定是最短)
        使用一個陣列from紀錄 節點之間的往返

        時間複雜度
        疏密圖(Adjacency List):O(V+E)--->(每個節點)*(與之相連接的節點)
        稠密圖(Adjacency Matrix):O(V^2)--->(每個節點)*(每個節點檢查是否相連)
    6.使用廣度優先遍歷 求無權圖的最短路徑
        使用一個陣列ord紀錄 路徑長度
        時間複雜度
        疏密圖(Adjacency List):O(V+E)--->(每個節點)*(與之相連接的節點)
        稠密圖(Adjacency Matrix):O(V^2)--->(每個節點)*(每個節點檢查是否相連)
    [DFS 與 BFS 時間複雜度與路徑問題]
        時間複雜度上DFS與BFS沒有區別
        但再遍歷的實作不同 找到的路徑也有不同
        DFS是找到 一條路徑
        而BFS是找到 最短路徑
    7.實際用途
        1.PS的區塊選取--->flood filled--->相鄰的像素點 構成的問題 ---> 詳情看影片
        2.掃雷遊戲--->flood filled
        3.迷宮生成--->本質是一棵樹
        4.歐拉路徑
        5.哈密爾頓路徑
        6.二分圖
        7.地圖填色問題

第八章-最小生成樹
    1.有權圖Weighted Graph:邊上帶有數值
        一樣分成
        疏密圖--->Adjacency List 實作
        稠密圖--->Adjacency Matrix 實作
        與圖論的實作大同小異
        但是在儲存 邊的訊息時 會有 相連結點 與 權重 兩個資訊
        使用一個類 來封裝 這樣的資訊
    2.最小生成樹(Minimum Span Tree)
        總共連接v個節點 使用(v-1)條邊連接成一棵樹
        還能使此樹所有邊的權重相加最小
        [用處]
            1.設計電纜的布線:使每區都有電力，又能最佳化節省電纜的電線成本
            2.網絡設計...等等等
        
        最小生成樹是針對 
        1.帶權重的無向圖
        2.針對連通圖(Component Graph)

        最小生成樹 一定要確保圖是 連通圖且不能有環
        (也就是 全部節點都可以連 而且 沒有自己連自己的邊)

        如果圖不連通(連通量>1)則 在每個子圖中 先找出 最小生成樹
        再將全部子圖的最小生成樹連在一起 會產生 最小生成森林

        [切分定理(Cut Property)]用來求最小生成樹
            先備知識
                1.切分(Cut)
                    把圖中的節點分成兩部分--->成為一個切分(Cut)
                2.橫切邊(Crossing Edge)
                    如果一個邊的兩個端點 屬於 不同的兩邊
                    則此邊叫做 橫切邊
            切分定理:
                在一張圖中 給定任意的切分，橫切邊中 權重最小的邊 必然屬於最小生成樹
        [Prim Algorithm]利用切分定理 求得最小生成樹
    3.Lazy Prim--->時間複雜度O(ElogE)--->E為邊
        Lazy Prim Lazy在 不會去除 那些 不可能成為最小生成樹的邊(兩個節點屬於同一個邊)

        算法過程
        1.建立一個最小堆 並選擇 最小生成樹的 第一個節點
        2.將節點與其他節點相連的邊 全部放入最小堆(Lazy在這裡:沒有過濾 不是橫切邊的邊)
        3.開始檢查 最小堆中 權重最小的元素
            如果是橫切邊--->將此邊連接到的節點加入最小樹 往步驟4
            如果不是橫切邊--->將此邊丟掉--->繼續找最小值 直到是橫切邊
        4.重複步驟2,3 直到整個圖的節點都被遍歷完
    4.使用IndexMinHeap優化Lazy Prim 使其成為Prim算法--->時間複雜度O(ElogV)--->E為邊V為節點
    5.Kruskal算法 求最小生成數--->O(ElogE)
        使用UnionFind的概念 檢查是否產生 『環』

        算法過程
        1.找到權重最小的邊 並檢查 是否會形成環
            會形成環--->丟棄
            不會形成環--->MST的邊
        2.重複步驟1
    6.時間複雜度
        Lazy Prim--->O(ElogE)
        Prim--->O(ElogV)
        Kruskal--->O(ElogE)

        以時間複雜度來說 Prim最好
        但以實作來說 Lazy Prim 與 Kruskal最好實作
        
        [整理]
            Lazy Prim 使用 MinHeap輔助 處理邊的問題 (放入新的可能的橫切邊 每次取出權重最小的邊)
            Prim 使用IndexMinHeap輔助 處理邊的問題(使用取代或加入 可能的橫切邊 每次取出權重最小的邊)
            Kruskal 使用MinHeap+UnionFind輔助 處理環的問題(檢查每個最小邊的兩個節點 是否屬於同一類)

        [比較]
        Prim算法 在 稠密圖 的效能較好
        Kruskal算法 在 稀疏圖 的效能較好

第九章-最短路徑
    1.最短路徑問題和鬆弛操作(Relaxation)
        最短路徑問題 適用在 有向圖 和 無向圖
        [功能]
            1.路徑規劃
            2.工作任務規劃

        最短路徑樹Shortest Path Tree
        每個節點 距離起始節點的權重是最小的
        也就是解決單源最短路徑(Single Source Shortest Path)
        單源: 起始點

        [比較]最小生成樹MST 與 最短路徑樹 SPT
            最小生成樹: 連接所有節點的邊 權重總和最低
            最短路徑樹: 所有節點距離起始節點的邊 權重最小
                       也就是起始節點連接到其他所有節點的邊 都要是權重總和最小

        在第七章學的是無權圖的最短路徑
        在這章要學的是 帶權圖的最短路徑

        帶權圖與無權圖的最短路徑差別
        
        假設A到C有兩條路
            第一條是 A先到B再到C 權重總和是0.5
            第二條是 A直接到C 權重總和是0.8

        對於無權圖來說 第二條是最短路徑(因為經過的邊最少)
        對於有權突來說 第一條是最短路徑(權重總和較低)

        [鬆弛操作(Relaxation)] 檢查某個節點的最短路徑問題
        假設有三個節點 編號 0,1,2
        要從0到2有兩條路
        第一條0-->2 總權重為5
        第二條0-->1-->2 總權重為4

        當我們是有權圖在找0到2的最短路徑時
        要去考慮 除了 直接0--->2以外
        是否還有其他可能 也就是經由其他節點的路徑
        來判斷 最短路徑 這就是 鬆弛操作
    2.Dijkstra 單源最短路徑算法--->時間複雜度O(Elog(V))
        [前提]:圖中的邊 權重不能為 負值
    3.負權重的單元最短路徑算法Bellman-Ford算法--->時間複雜度O(EV)
    4.處理所有無負權重環的所有對最短路徑(也就是任意指定兩點) Floyed算法--->時間複雜度O(V^3)